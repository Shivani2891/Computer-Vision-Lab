{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries"
      ],
      "metadata": {
        "id": "B8Nrqpcnlvze"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcbYuqHiCXhh"
      },
      "outputs": [],
      "source": [
        "# importing the libraries\n",
        "from torchsummary import summary\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from skimage.io import imread, imsave\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from scipy import ndimage"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-ITy8biLWHF",
        "outputId": "15db01d3-8fcd-4048-bb16-9188d03233f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "The dataset , I am working on is, emergency and non emergency vehicles images , which is available on kaggle.the datset has two files, one with 1646 images and the other .csv file with image name and the label.\n",
        "0 here represents that the vehicle is non-emergency and 1 means it’s an emergency vehicle. "
      ],
      "metadata": {
        "id": "DGfEliDVl7jL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading dataset\n",
        "data = pd.read_csv('/gdrive/MyDrive/emergency_vs_non-emergency_dataset/emergency_vs_non-emergency_dataset/emergency_train.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "38IVwcIsK3AN",
        "outputId": "1b4ad164-358d-4791-e8c7-39a2bc764848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_names</th>\n",
              "      <th>emergency_or_not</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1503.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1420.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1764.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1356.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1117.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image_names  emergency_or_not\n",
              "0    1503.jpg                 0\n",
              "1    1420.jpg                 0\n",
              "2    1764.jpg                 0\n",
              "3    1356.jpg                 0\n",
              "4    1117.jpg                 0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the dataset\n",
        "The dataset is loaded from the drive. The shape of training data shows, images are of the size 224*224 and channels are 3 that means images are coloured.\n"
      ],
      "metadata": {
        "id": "xlADt_-tmv86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading images\n",
        "train_img = []\n",
        "for img_name in tqdm(data['image_names']):\n",
        "    image_path = '/gdrive/MyDrive/emergency_vs_non-emergency_dataset/emergency_vs_non-emergency_dataset/images/' + img_name\n",
        "    img = imread(image_path)\n",
        "    img = img/255\n",
        "    train_img.append(img)\n",
        "\n",
        "train_x = np.array(train_img)\n",
        "train_y = data['emergency_or_not'].values\n",
        "train_x.shape, train_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vX8855icK3Dq",
        "outputId": "f769b42c-c37a-451c-e254-f3b937c9683d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1646/1646 [10:18<00:00,  2.66it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1646, 224, 224, 3), (1646,))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train-test split\n",
        "I have kept the test_size as 0.1 and hence 10% data will be randomly selected as the validation set and the remaining 90% will be used to train the model. We have 1,481 images in the training set which is quite less to train a deep learning model. I wanted to data augmentation for increasing the size of train data, but due to RAM limitation in colab, my session kept on crashing. So, had to drop that idea.\n",
        "\n",
        "Now, only 1481 images in train dataset.\n"
      ],
      "metadata": {
        "id": "lQkjCVISnaXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size = 0.1, random_state = 13, stratify=train_y)\n",
        "(train_x.shape, train_y.shape), (val_x.shape, val_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs1KARagK3HS",
        "outputId": "2f6aec51-2c93-4ba0-e7fb-3fcbead64ef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(((1481, 224, 224, 3), (1481,)), ((165, 224, 224, 3), (165,)))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the CNN Model using Pytorch"
      ],
      "metadata": {
        "id": "447xUMjan-tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch libraries and modules\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD"
      ],
      "metadata": {
        "id": "0qvOgKVpLiE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First,the images are converted to tensors."
      ],
      "metadata": {
        "id": "mE8H4MkMoJUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# converting training images into torch format\n",
        "#train_x = train_x.reshape(7405, 3, 224, 224)\n",
        "train_x  = torch.from_numpy(train_x)\n",
        "train_x = train_x.float()\n",
        "\n",
        "# converting the target into torch format\n",
        "train_y = train_y.astype(int)\n",
        "train_y = torch.from_numpy(train_y)\n"
      ],
      "metadata": {
        "id": "8zsE9rAwLiIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_x.shape) # train dataset shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vXaQJJiZ8pb",
        "outputId": "b901910c-d4c7-4c54-f957-d6d1e39ceb7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1481, 224, 224, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_x.reshape(1481,3,224,224) # reshaping it before it is fed into the model with number of channels ahead of the image size"
      ],
      "metadata": {
        "id": "hr6NWnBjaHs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "legRwIeHabrZ",
        "outputId": "109950a4-b841-4664-c4b7-f42569ad59e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1481, 3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### similar process is repeated with test/val dataset"
      ],
      "metadata": {
        "id": "pnNsJ26koptk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# converting validation images into torch format\n",
        "#val_x = val_x.reshape(165,224, 224,3)\n",
        "val_x  = torch.from_numpy(val_x)\n",
        "val_x = val_x.float()\n",
        "\n",
        "# converting the target into torch format\n",
        "val_y = val_y.astype(int)\n",
        "val_y = torch.from_numpy(val_y)"
      ],
      "metadata": {
        "id": "4THgQ5y6LiLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH-SNm0lZ458",
        "outputId": "09be95bd-f08f-4505-c0d3-87f424602eae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([165, 224, 224, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the architecture of CNN model\n",
        "The architecture has 4 convolutional blocks and then 4 fully connected dense layers. The kernel size is 3, padding and stride  size are  1 for all the convolutional layers.After every convolutional layer, ReLu activation function is ised.\n",
        "To avoid overfitting andrandomize the dataset, dropout of 0.25 is used after every convolutional layer and Linear layer.\n",
        "For regularization and to make training more efficient,batch normalization layer is also used afterevery convolutional layer.\n"
      ],
      "metadata": {
        "id": "PjdALQsjo_Z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "class Net(Module):   \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.cnn_layers = Sequential(\n",
        "            # Defining a 2D convolution layer\n",
        "            Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            ReLU(inplace=True),\n",
        "            # adding batch normalization\n",
        "            BatchNorm2d(32),\n",
        "            MaxPool2d(kernel_size=2, stride=2),\n",
        "            # adding dropout\n",
        "            Dropout(p=0.25),\n",
        "            # Defining another 2D convolution layer\n",
        "            Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            ReLU(inplace=True),\n",
        "            # adding batch normalization\n",
        "            BatchNorm2d(64),\n",
        "            MaxPool2d(kernel_size=2, stride=2),\n",
        "            # adding dropout\n",
        "            Dropout(p=0.25),\n",
        "            # Defining another 2D convolution layer\n",
        "            Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            ReLU(inplace=True),\n",
        "            # adding batch normalization\n",
        "            BatchNorm2d(128),\n",
        "            MaxPool2d(kernel_size=2, stride=2),\n",
        "            # adding dropout\n",
        "            Dropout(p=0.25),\n",
        "            # Defining another 2D convolution layer\n",
        "            Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            ReLU(inplace=True),\n",
        "            # adding batch normalization\n",
        "            BatchNorm2d(128),\n",
        "            MaxPool2d(kernel_size=2, stride=2),\n",
        "            # adding dropout\n",
        "            Dropout(p=0.25),\n",
        "        )\n",
        "\n",
        "        self.linear_layers = Sequential(\n",
        "            Linear(128 * 14 * 14, 512),\n",
        "            ReLU(inplace=True),\n",
        "            Dropout(),\n",
        "            Linear(512, 256),\n",
        "            ReLU(inplace=True),\n",
        "            Dropout(),\n",
        "            Linear(256,10),\n",
        "            ReLU(inplace=True),\n",
        "            Dropout(),\n",
        "            Linear(10,2)\n",
        "        )\n",
        "\n",
        "    # Defining the forward pass    \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear_layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "3ORbOSPAL8kG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the model\n",
        "model = Net()\n",
        "# defining the optimizer\n",
        "optimizer = Adam(model.parameters(), lr=0.000075)\n",
        "# defining the loss function\n",
        "criterion = CrossEntropyLoss()\n",
        "# checking if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3kju5v3L8pu",
        "outputId": "f51cd58a-076f-4681-d093-0f5802e138ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (cnn_layers): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Dropout(p=0.25, inplace=False)\n",
            "    (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (9): Dropout(p=0.25, inplace=False)\n",
            "    (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Dropout(p=0.25, inplace=False)\n",
            "    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (19): Dropout(p=0.25, inplace=False)\n",
            "  )\n",
            "  (linear_layers): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=512, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=256, out_features=10, bias=True)\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Dropout(p=0.5, inplace=False)\n",
            "    (9): Linear(in_features=10, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "# batch size of the model\n",
        "batch_size = 64\n",
        "\n",
        "# number of epochs to train the model\n",
        "n_epochs = 20\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "\n",
        "    train_loss = 0.0\n",
        "        \n",
        "    permutation = torch.randperm(train_x.size()[0])\n",
        "\n",
        "    training_loss = []\n",
        "    for i in tqdm(range(0,train_x.size()[0], batch_size)):\n",
        "\n",
        "        indices = permutation[i:i+batch_size]\n",
        "        batch_x, batch_y = train_x[indices], train_y[indices]\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_x)\n",
        "        loss = criterion(outputs,batch_y)\n",
        "\n",
        "        training_loss.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    training_loss = np.average(training_loss)\n",
        "    print('epoch: \\t', epoch, '\\t training loss: \\t', training_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GST4vWHfMMor",
        "outputId": "d7eb2bf4-0c32-4e0b-c528-a58aeba94da6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:07<00:00,  3.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: \t 1 \t training loss: \t 0.6822157576680183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:06<00:00,  3.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: \t 2 \t training loss: \t 0.6759209657708803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:06<00:00,  3.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: \t 3 \t training loss: \t 0.6541100268562635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:06<00:00,  3.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: \t 4 \t training loss: \t 0.6574761544664701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:06<00:00,  3.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: \t 5 \t training loss: \t 0.652056097984314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:06<00:00,  3.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: \t 6 \t training loss: \t 0.632632665336132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:06<00:00,  3.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: \t 7 \t training loss: \t 0.6356366872787476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:06<00:00,  3.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: \t 8 \t training loss: \t 0.6025484589238962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:06<00:00,  3.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: \t 9 \t training loss: \t 0.5840324821571509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:06<00:00,  3.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: \t 10 \t training loss: \t 0.5828275506695112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:06<00:00,  3.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: \t 11 \t training loss: \t 0.5555670162041982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:06<00:00,  3.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: \t 12 \t training loss: \t 0.5466223085920016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:06<00:00,  3.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: \t 13 \t training loss: \t 0.5382725621263186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:06<00:00,  3.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: \t 14 \t training loss: \t 0.536979558567206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:06<00:00,  3.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: \t 15 \t training loss: \t 0.4938240436216195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:06<00:00,  3.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: \t 16 \t training loss: \t 0.5282910193006197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:06<00:00,  3.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: \t 17 \t training loss: \t 0.49292944620052975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:06<00:00,  3.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: \t 18 \t training loss: \t 0.4779381876190503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:06<00:00,  3.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: \t 19 \t training loss: \t 0.4670604070027669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:06<00:00,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: \t 20 \t training loss: \t 0.428358007222414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "# prediction for training set\n",
        "prediction = []\n",
        "target = []\n",
        "permutation = torch.randperm(train_x.size()[0])\n",
        "for i in tqdm(range(0,train_x.size()[0], batch_size)):\n",
        "    indices = permutation[i:i+batch_size]\n",
        "    batch_x, batch_y = train_x[indices],train_y[indices]\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(batch_x).cuda()\n",
        "\n",
        "    softmax = torch.exp(output).cpu()\n",
        "    prob = list(softmax.numpy())\n",
        "    predictions = np.argmax(prob, axis=1)\n",
        "    prediction.append(predictions)\n",
        "    target.append(batch_y)\n",
        "    \n",
        "# training accuracy\n",
        "accuracy = []\n",
        "for i in range(len(prediction)):\n",
        "    accuracy.append(accuracy_score(target[i].cpu(),prediction[i]))\n",
        "    \n",
        "print('training accuracy: \\t', np.average(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkZn0yKZL8s9",
        "outputId": "256f4ad8-cb57-4833-9532-5cf905eb2372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:02<00:00,  9.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training accuracy: \t 0.8064959490740741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIi6J3Ym7hwP",
        "outputId": "110f3bc6-3737-46cd-feba-1e30e487cc00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([165, 224, 224, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_x=val_x.reshape(165,3,224,224)"
      ],
      "metadata": {
        "id": "Voz2ArE87poz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the performance on validation set\n",
        "torch.manual_seed(0)\n",
        "output = model(val_x.cuda())\n",
        "softmax = torch.exp(output).cpu()\n",
        "prob = list(softmax.detach().numpy())\n",
        "predictions = np.argmax(prob, axis=1)\n",
        "accuracy_score(val_y, predictions)"
      ],
      "metadata": {
        "id": "ixXXxItBzHjV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edaf1e3b-fa76-4bc0-eb9d-2ca77afb3575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.703030303030303"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}